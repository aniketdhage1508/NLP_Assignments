{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Write a better auto-complete algorithm using an N-gram model (similar models are used for translation, determining the author of a text, and speech recognition)**"
      ],
      "metadata": {
        "id": "n53AX2n0wW1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK tokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eEBIxn3se1P",
        "outputId": "8bbfd277-8ce3-4b84-cd32-5284bdc97ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and tokenizes input text.\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove punctuation\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "h9JnJ6Frssyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ngram_model(text, n=2):\n",
        "    \"\"\"\n",
        "    Trains an N-Gram model on input text and returns necessary data structures.\n",
        "    \"\"\"\n",
        "    tokens = preprocess_text(text)\n",
        "    vocab = set(tokens)\n",
        "    unigram_counts = Counter(tokens)\n",
        "    ngram_counts = defaultdict(Counter)\n",
        "\n",
        "    # Create n-grams\n",
        "    n_grams = list(ngrams(tokens, n, pad_left=True, pad_right=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
        "\n",
        "    # Count occurrences\n",
        "    for ngram in n_grams:\n",
        "        prefix = tuple(ngram[:-1])  # Previous words\n",
        "        next_word = ngram[-1]       # Next word prediction\n",
        "        ngram_counts[prefix][next_word] += 1\n",
        "\n",
        "    return ngram_counts, unigram_counts, vocab"
      ],
      "metadata": {
        "id": "T0y8Klm9suQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(text, ngram_counts, unigram_counts, vocab, n=2):\n",
        "    \"\"\"\n",
        "    Predicts the most likely next word given a phrase.\n",
        "    \"\"\"\n",
        "    tokens = preprocess_text(text)\n",
        "    prefix = tuple(tokens[-(n - 1):])  # Get the last N-1 words as prefix\n",
        "\n",
        "    # If prefix exists in n-grams, predict based on probability\n",
        "    if prefix in ngram_counts:\n",
        "        probable_words = ngram_counts[prefix]\n",
        "        total_count = sum(probable_words.values())\n",
        "        choices, weights = zip(*[(word, count / total_count) for word, count in probable_words.items()])\n",
        "        return random.choices(choices, weights=weights)[0]\n",
        "\n",
        "    # Fallback: Predict based on unigram probabilities\n",
        "    elif unigram_counts:\n",
        "        choices, weights = zip(*[(word, count / sum(unigram_counts.values())) for word, count in unigram_counts.items()])\n",
        "        return random.choices(choices, weights=weights)[0]\n",
        "\n",
        "    # Last fallback: Random word from vocabulary\n",
        "    return random.choice(list(vocab)) if vocab else \"No prediction available\""
      ],
      "metadata": {
        "id": "drGu_lxBswA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_corpus = \"\"\"\n",
        "Machine Learning is a subset of Artificial Intelligence that enables systems to learn and improve from experience.\n",
        "Text prediction models are widely used in modern applications, including search engines and messaging platforms.\n",
        "The n-gram approach is a fundamental technique in NLP for generating text-based predictions.\n",
        "\"\"\"\n",
        "\n",
        "ngram_counts, unigram_counts, vocab = train_ngram_model(text_corpus, n=2)  # Bigram Model\n",
        "\n",
        "# Test Auto-complete\n",
        "test_sentences = [\"Machine Learning\", \"Text prediction\", \"The n-gram\", \"Artificial Intelligence is\", \"Systems to\"]\n",
        "\n",
        "print(\"\\n=== N-Gram Auto-Complete Predictions ===\\n\")\n",
        "for sentence in test_sentences:\n",
        "    predicted_word = predict_next_word(sentence, ngram_counts, unigram_counts, vocab, n=2)\n",
        "    print(f\"Input: \\033[1;34m'{sentence}'\\033[0m → Predicted Next Word: \\033[1;32m'{predicted_word}'\\033[0m\")\n",
        "print(\"\\n========================================\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9_gQREPr5Qm",
        "outputId": "f112f05b-f563-4629-dbfa-033c88b8add7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== N-Gram Auto-Complete Predictions ===\n",
            "\n",
            "Input: \u001b[1;34m'Machine Learning'\u001b[0m → Predicted Next Word: \u001b[1;32m'is'\u001b[0m\n",
            "Input: \u001b[1;34m'Text prediction'\u001b[0m → Predicted Next Word: \u001b[1;32m'models'\u001b[0m\n",
            "Input: \u001b[1;34m'The n-gram'\u001b[0m → Predicted Next Word: \u001b[1;32m'approach'\u001b[0m\n",
            "Input: \u001b[1;34m'Artificial Intelligence is'\u001b[0m → Predicted Next Word: \u001b[1;32m'a'\u001b[0m\n",
            "Input: \u001b[1;34m'Systems to'\u001b[0m → Predicted Next Word: \u001b[1;32m'learn'\u001b[0m\n",
            "\n",
            "========================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}